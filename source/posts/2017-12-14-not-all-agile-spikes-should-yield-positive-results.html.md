---
layout: article
title: "Not all spikes yield positive results"
date_created_on: 2017-12-14 07:30 AM
date_published_on: 2017-12-14 07:30 AM
date_modified_on: 2017-12-14 07:30 AM
tags:
  - opinion
published: true
author: "Adrian Oprea"
twitter: "@oprearocks"
keywords: agile spikes, scrum spikes, research, extreme programming spikes
image: /images/posts/not-all-agile-spikes-should-yield-positive-results/post.jpg
---

If you're working with almost any AGILE methodology you probably know what a Spike is. For those of you that don't know, here's a definition straight out of [THE AGILE DICTIONARY](http://agiledictionary.com/209/spike/):

> A task aimed at answering a question or gathering information, rather than at producing shippable product. Sometimes a user story is generated that cannot be well estimated until the development team does some actual work to resolve a technical question or a design problem. The solution is to create a “spike,” which is some work whose purpose is to provide the answer or solution.
> [...]
> The term spike comes from Extreme Programming (XP), where “A spike solution is a very simple program to explore potential solutions.” XP guru Ward Cunningham describes how the term was coined on the C2.com wiki: “I would often ask Kent [Beck], ‘What is the simplest thing we can program that will convince us we are on the right track?’ Such stepping outside the difficulties at hand often led us to simpler and more compelling solutions. Kent dubbed this a Spike. I found the practice particularly useful while maintaining large frameworks.”

READMORE

Let's say you plan on migrating your platform to a new technology. Let's assume that you find out about a piece of software that could solve part of your migration problems. 

If you go ahead and research that technology and find out that it doesn't fit, that is not wasted time. 

Think of it like this:

Would you rather start working with a new "thing" without knowing anything besides what the software's documentation page would tell you, and spend 3 weeks trying to implement it? Only to find out that it doesn't fit your needs, or the learning curve is too steep? 

It's better to spend 2 days on research and invalidate something, than to spend 3 weeks "figuring it out" and then invalidate it. This saves you from the sunk cost fallacy as well. Because if you put in 3 weeks of work, chances are that the team will force you into a death march. They already have "good work" there and they're reluctant to throw that away.

So expect spikes to produce throwaway work, and negative results. Welcome that.

Cheers!

> Photo credits:
>
> [DaPuglet](https://www.flickr.com/photos/unitedsoybean/) &mdash; [Biodiesel Research](https://flic.kr/p/gXYJnZ)
